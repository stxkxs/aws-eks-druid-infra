hostId: "host"
hostedId: "hosted"
account: "111111111111"
region: "us-west-2"
type: "default"
environment: "prototype"
name: "druid"
alias: "alias"
build: "v1"
domain: "data.stxkxs.io"
organization: "stxkxs"

image:
  tag: 33.0.0
  repository: apache/druid
  pullPolicy: Always

labels:
  "data.stxkxs.io/account": "111111111111"
  "data.stxkxs.io/region": "us-west-2"
  "data.stxkxs.io/billing": "stxkxs"
  "data.stxkxs.io/build": "v1"
  "data.stxkxs.io/stack": "default-prototype"
  "data.stxkxs.io/resource-type": druid
  "data.stxkxs.io/category": compute.storage
  "data.stxkxs.io/type": analytics
  "data.stxkxs.io/part-of": "druid"
  "data.stxkxs.io/name": "druid"

annotations:
  "k8s.grafana.com/scrape": "true"
  "k8s.grafana.com/metrics.portNumber": "9000"

securityContext:
  fsGroup: 1000
  runAsUser: 1000
  runAsGroup: 1000

runtime: |-
  # https://druid.apache.org/docs/latest/configuration/
  
  druid.startup.logging.logProperties=true
  druid.server.hiddenProperties=["druid.s3.accessKey","druid.s3.secretKey","druid.metadata.storage.connector.password", "password", "key", "token", "pwd"]
  
  # extensions
  # https://druid.apache.org/docs/latest/configuration/extensions
  druid.extensions.loadList=["simple-client-sslcontext", "druid-basic-security", "druid-s3-extensions", "druid-aws-rds-extensions", "postgresql-metadata-storage", "druid-multi-stage-query", "druid-kafka-indexing-service", "prometheus-emitter", "druid-kubernetes-extensions", "druid-kubernetes-overlord-extensions"]
  
  # authn/authz + default users
  # https://druid.apache.org/docs/latest/configuration/#authentication-and-authorization
  # https://druid.apache.org/docs/latest/operations/security-user-auth
  druid.auth.authenticatorChain=["authn-druid-v1"]
  druid.auth.authenticator.authn-druid-v1.type=basic
  druid.auth.authorizer.authz-druid-v1.type=basic
  druid.auth.authenticator.authn-druid-v1.skipOnFailure=false
  druid.auth.authenticator.authn-druid-v1.credentialsValidator.type=metadata
  druid.auth.authenticator.authn-druid-v1.authorizerName=authz-druid-v1
  druid.escalator.type=basic
  druid.escalator.authorizerName=authz-druid-v1
  druid.auth.authorizers=["authz-druid-v1"]
  druid.auth.authenticator.authn-druid-v1.initialAdminPassword=${env:DRUID_ADMIN_PASSWORD}
  druid.escalator.internalClientUsername=${env:DRUID_SYSTEM_USERNAME}
  druid.escalator.internalClientPassword=${env:DRUID_SYSTEM_PASSWORD}
  druid.auth.authenticator.authn-druid-v1.initialInternalClientPassword=${env:DRUID_SYSTEM_PASSWORD}
  
  # tls
  # https://druid.apache.org/docs/latest/operations/security-overview
  # https://druid.apache.org/docs/latest/configuration/#tls
  # https://druid.apache.org/docs/latest/operations/tls-support/
  druid.enableTlsPort=true
  druid.enablePlaintextPort=false
  druid.server.https.keyStorePath=/opt/druid/conf/druid/cluster/tls/server-keystore.p12
  druid.server.https.keyStoreType=pkcs12
  druid.server.https.certAlias=druid-server
  druid.server.https.keyManagerPassword=changeit
  druid.server.https.keyStorePassword=changeit
  druid.server.https.reloadSslContext=true
  druid.server.https.reloadSslContextSeconds=180
  druid.server.https.requestClientCertificate=true
  druid.server.https.trustStoreType=pkcs12
  druid.server.https.trustStorePath=/opt/druid/conf/druid/cluster/tls/server-truststore.p12
  druid.server.https.trustStorePassword=changeit
  druid.server.https.validateHostnames=false
  druid.client.https.keyStorePath=/opt/druid/conf/druid/cluster/tls/client-keystore.p12
  druid.client.https.keyStoreType=pkcs12
  druid.client.https.certAlias=druid-client
  druid.client.https.keyStorePassword=changeit
  druid.client.https.keyManagerPassword=changeit
  druid.client.https.validateHostnames=false
  druid.client.https.protocol=TLSv1.2
  druid.client.https.trustStoreType=pkcs12
  druid.client.https.trustStorePath=/opt/druid/conf/druid/cluster/tls/client-truststore.p12
  druid.client.https.trustStorePassword=changeit
  
  # druid kubernetes extensions [zookeeper-less]
  # https://druid.apache.org/docs/latest/development/extensions-core/kubernetes/
  druid.discovery.type=k8s
  druid.zk.service.enabled=false
  druid.discovery.k8s.clusterIdentifier=eks-druid-v1
  druid.serverview.type=http
  druid.indexer.runner.type=httpRemote
  
  # index storage
  # https://druid.apache.org/docs/latest/configuration/#task-logging
  druid.indexer.logs.type=s3
  druid.indexer.logs.disableAcl=true
  druid.indexer.logs.s3Prefix=druid/indexing-logs
  druid.indexer.logs.s3Bucket=druid-druid-v1-indexlogs
  
  # metadata storage
  # https://druid.apache.org/docs/latest/configuration/#metadata-storage
  druid.metadata.storage.type=postgresql
  druid.metadata.storage.connector.user=${env:DRUID_METADATA_STORAGE_USERNAME}
  druid.metadata.storage.connector.password=${env:DRUID_METADATA_STORAGE_PASSWORD}
  druid.metadata.storage.connector.connectURI=jdbc:postgresql://${env:DRUID_METADATA_STORAGE_HOST}/druid_metadata
  druid.metadata.storage.connector.createTables=true
  druid.metadata.storage.tables.base=druid
  druid.metadata.storage.tables.audit=druid_audit
  druid.metadata.storage.tables.dataSource=druid_data_source
  druid.metadata.storage.tables.pendingSegments=druid_pending_segments
  druid.metadata.storage.tables.segments=druid_segments
  druid.metadata.storage.tables.rules=druid_rules
  druid.metadata.storage.tables.config=druid_config
  druid.metadata.storage.tables.tasks=druid_tasks
  druid.metadata.storage.tables.taskLog=druid_task_logs
  druid.metadata.storage.tables.taskLock=druid_task_locks
  druid.metadata.storage.tables.supervisors=druid_supervisors
  
  # deep storage
  # https://druid.apache.org/docs/latest/configuration/#deep-storage
  druid.storage.type=s3
  druid.storage.disableAcl=true
  druid.storage.baseKey=druid/segments
  druid.storage.bucket=druid-druid-v1-deepstorage
  
  # multi-stage query durable storage
  # https://druid.apache.org/docs/latest/operations/durable-storage/
  druid.msq.intermediate.storage.enable=true
  druid.msq.intermediate.storage.tempDir=/var/druid/msq
  druid.msq.intermediate.storage.cleaner.enabled=true
  druid.msq.intermediate.storage.type=s3
  druid.msq.intermediate.storage.prefix=druid/msq
  druid.msq.intermediate.storage.bucket=druid-yeet-v1-msq
  
  # monitoring
  # https://druid.apache.org/docs/latest/configuration/#enabling-metrics
  druid.emitter=composing
  druid.emitter.logging.logLevel=debug
  druid.emitter.composing.emitters=["logging","prometheus"]
  druid.emitter.prometheus.port=9000
  druid.emitter.prometheus.strategy=exporter
  druid.emitter.prometheus.addHostAsLabel=true
  druid.emitter.prometheus.addServiceAsLabel=true
  
  druid.monitoring.monitors=["org.apache.druid.java.util.metrics.JvmMonitor", "org.apache.druid.server.metrics.ServiceStatusMonitor"]

env:
  - name: AWS_REGION
    value: "us-west-2"
  - name: HOSTNAME
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.name
  - name: POD_NAME
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.name
  - name: POD_NAMESPACE
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.namespace
  - name: DRUID_METADATA_STORAGE_USERNAME
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-metadata
        key: username
  - name: DRUID_METADATA_STORAGE_PASSWORD
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-metadata
        key: password
  - name: DRUID_METADATA_STORAGE_DBNAME
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-metadata
        key: dbname
  - name: DRUID_METADATA_STORAGE_HOST
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-metadata
        key: host
  - name: DRUID_METADATA_STORAGE_CONNECT_URI
    value: jdbc:postgresql://$(DRUID_METADATA_STORAGE_HOST)/$(DRUID_METADATA_STORAGE_DBNAME)
  - name: DRUID_ADMIN_USERNAME
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-admin
        key: username
  - name: DRUID_ADMIN_PASSWORD
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-admin
        key: password
  - name: DRUID_SYSTEM_USERNAME
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-system
        key: username
  - name: DRUID_SYSTEM_PASSWORD
    valueFrom:
      secretKeyRef:
        name: druid-yeet-v1-system
        key: password

volumes:
  - name: druid-scratch
    emptyDir: { }
  - name: druid-common-conf
    configMap:
      name: "druid-yeet-v1-common-conf"
  - name: druid-tls
    secret:
      secretName: "druid-yeet-v1-tls"
      items:
        - key: client-keystore.p12
          path: client-keystore.p12
        - key: client-truststore.p12
          path: client-truststore.p12
        - key: client.crt
          path: client.crt
        - key: server-keystore.p12
          path: server-keystore.p12
        - key: server-truststore.p12
          path: server-truststore.p12
        - key: server.crt
          path: server.crt
  - name: druid-credentials
    csi:
      driver: secrets-store.csi.k8s.io
      readOnly: true
      volumeAttributes:
        secretProviderClass: "druid-v1-secretprovider"

volumeMounts:
  - mountPath: /opt/druid/conf/druid/cluster/_common
    name: druid-common-conf
    readOnly: true
  - mountPath: /opt/druid/conf/druid/cluster/credentials
    name: druid-credentials
    readOnly: true
  - mountPath: /opt/druid/conf/druid/cluster/tls
    name: druid-tls
    readOnly: true
  - mountPath: /var/druid
    name: druid-scratch
    readOnly: false

zookeeper:
  replicas: 3
  image:
    repository: confluentinc/cp-zookeeper
    tag: "7.4.0"
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  storage:
    dataStorageClass: "gp2"
    dataSize: "10Gi"
    logsStorageClass: "gp2"
    logsSize: "5Gi"
  volumes: []
  volumeMounts: []
  node:
    limits:
      cpu: 1000
    disruption:
      consolidationPolicy: WhenEmpty
      consolidateAfter: 30s
    requirements: []
    selector: {}
  podDisruptionBudget:
    maxUnavailable: 1
  metadata:
    labels: {}
    annotations: {}

router:
  metadata:
    labels: { }
    annotations:
      "k8s.grafana.com/job": "integrations/druid-router"
  replicas: 1
  resources:
    requests:
      cpu: 250m
      memory: 250Mi
    limits:
      cpu: 1500m
      memory: 1Gi
  node:
    selector:
      "karpenter.k8s.aws/instance-family": "t3a"
    limits:
      cpu: 50
      memory: 500Gi
    disruption:
      consolidateAfter: 10m
      consolidationPolicy: WhenEmpty
    requirements:
      - key: "karpenter.k8s.aws/instance-family"
        operator: In
        values: [ "t3a" ]
  volumes:
    - name: druid-router-conf
      configMap:
        name: "druid-v1-router-conf"
  volumeMounts:
    - name: druid-router-conf
      mountPath: /opt/druid/conf/druid/cluster/query/router
      readOnly: true
  runtime: |-
    druid.bindOnHost=false
    druid.tlsPort=9088
    druid.service=druid/router
    druid.router.defaultBrokerServiceName=druid/broker
    druid.router.tierToBrokerMap={"_default_tier": "druid/broker"}
    druid.router.defaultRule=_default
    druid.router.pollPeriod=PT1H
    druid.router.sql.enable=false
    druid.router.strategies=[{"type":"timeBoundary"},{"type":"priority"}]
    druid.router.avatica.balancer.type=rendezvousHash
    druid.router.managementProxy.enabled=true
    druid.router.http.numConnections=20
    druid.router.http.eagerInitialization=false
    druid.router.http.readTimeout=PT60M
    druid.router.http.numMaxThreads=32
    druid.router.http.numRequestsQueued=1000
    druid.router.http.requestBuffersize=10000
  jvm: |-
    -Xms512m
    -Xmx512m
    -XX:MaxDirectMemorySize=128m

broker:
  metadata:
    labels: { }
    annotations:
      "k8s.grafana.com/job": integrations/druid-broker
  replicas: 1
  resources:
    requests:
      cpu: 1500m
      memory: 7Gi
    limits:
      cpu: 6000m
      memory: 28Gi
  node:
    selector:
      "karpenter.k8s.aws/instance-family": "m5"
    limits:
      cpu: 100
      memory: 1000Gi
    disruption:
      consolidateAfter: 10m
      consolidationPolicy: WhenEmpty
    requirements:
      - key: "karpenter.k8s.aws/instance-family"
        operator: In
        values: [ "m5" ]
  volumes:
    - name: druid-broker-conf
      configMap:
        name: "druid-v1-broker-conf"
  volumeMounts:
    - name: druid-broker-conf
      mountPath: /opt/druid/conf/druid/cluster/query/broker
      readOnly: true
  runtime: |-
    druid.bindOnHost=false
    druid.tlsPort=8282
    druid.service=druid/broker
    druid.broker.balancer.type=random
    druid.broker.select.tier=highestPriority
    druid.query.scheduler.numThreads=38
    druid.query.scheduler.laning.strategy=none
    druid.query.scheduler.prioritization.strategy=manual
    druid.server.http.numThreads=38
    druid.server.http.maxIdleTime=PT5M
    druid.server.http.enableRequestLimit=false
    druid.server.http.defaultQueryTimeout=300000
    druid.server.http.maxSubqueryRows=100000
    druid.server.http.gracefulShutdownTimeout=PT30S
    druid.server.http.unannouncePropagationDelay=PT0S
    druid.server.http.maxRequestHeaderSize=10000
    druid.server.http.enableHSTS=false
    druid.broker.http.numConnections=20
    druid.broker.http.eagerInitialization=true
    druid.broker.http.compressionCodec=gzip
    druid.broker.http.readTimeout=PT45M
    druid.broker.http.unusedConnectionTimeout=PT4M
    druid.broker.http.maxQueuedBytes=62500000
    druid.broker.http.numMaxThreads=35
    druid.broker.retryPolicy.numTries=1
    druid.processing.buffer.sizeBytes=125000000
    druid.processing.buffer.poolCacheInitialCount=0
    druid.processing.numMergeBuffers=8
    druid.processing.fifo=true
    druid.processing.tmpDir=/var/druid/query/tmp
    druid.processing.merge.useParallelMergePool=true
    druid.processing.merge.pool.awaitShutdownMillis=60000
    druid.processing.merge.task.targetRunTimeMillis=100
    druid.processing.merge.task.initialYieldNumRows=16384
    druid.processing.merge.task.smallBatchNumRows=4096
    druid.sql.enable=true
    druid.sql.avatica.enable=true
    druid.sql.avatica.maxConnections=20
    druid.sql.avatica.maxRowsPerFrame=5000
    druid.sql.avatica.minRowsPerFrame=100
    druid.sql.avatica.maxStatementsPerConnection=4
    druid.sql.avatica.connectionIdleTimeout=PT5M
    druid.sql.avatica.fetchTimeoutMs=5000
    druid.sql.http.enable=true
    druid.sql.planner.maxTopNLimit=100000
    druid.sql.planner.metadataRefreshPeriod=PT1M
    druid.sql.planner.metadataColumnTypeMergePolicy=leastRestrictive
    druid.sql.planner.useApproximateCountDistinct=true
    druid.sql.planner.useGroupingSetForExactDistinct=false
    druid.sql.planner.useApproximateTopN=true
    druid.sql.planner.requireTimeCondition=false
    druid.sql.planner.sqlTimeZone=UTC
    druid.sql.planner.metadataSegmentCacheEnable=false
    druid.sql.planner.metadataSegmentPollPeriod=60000
    druid.sql.planner.authorizeSystemTablesDirectly=false
    druid.sql.planner.useNativeQueryExplain=true
    druid.sql.planner.maxNumericInFilters=-1
    druid.sql.approxCountDistinct.function=APPROX_COUNT_DISTINCT_BUILTIN
    druid.broker.cache.useCache=false
    druid.broker.cache.populateCache=false
    druid.broker.cache.useResultLevelCache=false
    druid.broker.cache.populateResultLevelCache=false
    druid.broker.cache.maxEntrySize=1000000
    druid.broker.segment.watchRealtimeTasks=true
    druid.broker.segment.awaitInitializationOnStart=true
    druid.monitoring.monitors=["org.apache.druid.java.util.metrics.JvmMonitor", "org.apache.druid.java.util.metrics.JvmCpuMonitor", "org.apache.druid.java.util.metrics.JvmThreadsMonitor", "org.apache.druid.server.metrics.HistoricalMetricsMonitor"]
  jvm: |-
    -Xms8g
    -Xmx8g
    -XX:MaxDirectMemorySize=8g

coordinator:
  metadata:
    labels: { }
    annotations:
      "k8s.grafana.com/job": "integrations/druid-coordinator"
  replicas: 1
  resources:
    requests:
      cpu: 1500m
      memory: 7Gi
    limits:
      cpu: 2500m
      memory: 12Gi
  node:
    selector:
      "karpenter.k8s.aws/instance-family": "m5"
    limits:
      cpu: 50
      memory: 500Gi
    disruption:
      consolidateAfter: 10m
      consolidationPolicy: WhenEmpty
    requirements:
      - key: "karpenter.k8s.aws/instance-family"
        operator: In
        values: [ "m5" ]
  volumes:
    - name: druid-coordinator-conf
      configMap:
        name: "druid-v1-coordinator-conf"
  volumeMounts:
    - name: druid-coordinator-conf
      mountPath: /opt/druid/conf/druid/cluster/master/coordinator-overlord
      readOnly: true
  runtime: |-
    druid.bindOnHost=false
    druid.tlsPort=8281
    druid.service=druid/coordinator
    druid.coordinator.period=PT30S
    druid.coordinator.period.indexingPeriod=PT1800S
    druid.coordinator.startDelay=PT30S
    druid.coordinator.load.timeout=PT60M
    druid.coordinator.kill.pendingSegments.on=false
    druid.coordinator.kill.on=false
    druid.coordinator.kill.period=P1D
    druid.coordinator.kill.durationToRetain=P90D
    druid.coordinator.kill.ignoreDurationToRetain=false
    druid.coordinator.kill.bufferPeriod=P30D
    druid.coordinator.kill.maxSegments=100
    druid.coordinator.balancer.strategy=cost
    druid.coordinator.balancer.cachingCost.awaitInitialization=false
    druid.coordinator.loadqueuepeon.repeatDelay=PT0.050S
    druid.coordinator.asOverlord.enabled=false
    druid.centralizedDatasourceSchema.enabled=false
    druid.coordinator.period.metadataStoreManagementPeriod=PT1H
    druid.coordinator.kill.supervisor.on=true
    druid.coordinator.kill.supervisor.period=P1D
    druid.coordinator.kill.supervisor.durationToRetain=P90D
    druid.coordinator.kill.audit.on=true
    druid.coordinator.kill.audit.period=P1D
    druid.coordinator.kill.audit.durationToRetain=P90D
    druid.coordinator.kill.compaction.on=true
    druid.coordinator.kill.compaction.period=P1D
    druid.coordinator.kill.rule.on=true
    druid.coordinator.kill.rule.period=P1D
    druid.coordinator.kill.rule.durationToRetain=P90D
    druid.coordinator.kill.datasource.on=true
    druid.coordinator.kill.datasource.period=P1D
    druid.coordinator.kill.datasource.durationToRetain=P90D
    druid.coordinator.loadqueuepeon.type=http
    druid.coordinator.segment.awaitInitializationOnStart=true
    druid.coordinator.loadqueuepeon.http.batchSize=1
    druid.manager.config.pollDuration=PT1M
    druid.manager.segments.pollDuration=PT1M
    druid.manager.rules.pollDuration=PT1M
    druid.manager.rules.defaultRule=_default
    druid.manager.rules.alertThreshold=PT10M
  jvm: |-
    -Xms6g
    -Xmx6g

overlord:
  metadata:
    labels: { }
    annotations:
      "k8s.grafana.com/job": "integrations/druid-overlord"
  replicas: 1
  resources:
    requests:
      cpu: 1500m
      memory: 7Gi
    limits:
      cpu: 2500m
      memory: 12Gi
  node:
    selector:
      "karpenter.k8s.aws/instance-family": "m5"
    limits:
      cpu: 50
      memory: 500Gi
    disruption:
      consolidateAfter: 10m
      consolidationPolicy: WhenEmpty
    requirements:
      - key: "karpenter.k8s.aws/instance-family"
        operator: In
        values: [ "m5" ]
  volumes:
    - name: druid-overlord-conf
      configMap:
        name: "druid-v1-overlord-conf"
        defaultMode: 420
    - name: druid-task-template
      configMap:
        name: "druid-v1-task-base-template"
        defaultMode: 420
  volumeMounts:
    - name: druid-overlord-conf
      mountPath: /opt/druid/conf/druid/cluster/master/coordinator-overlord
      readOnly: true
    - name: druid-task-template
      mountPath: /opt/druid/conf/druid/cluster/task/task-base.yaml
      subPath: task-base.yaml
      readOnly: true
  runtime: |-
    druid.bindOnHost=false
    druid.tlsPort=8290
    druid.service=druid/overlord
    druid.indexer.runner.type=k8s
    druid.indexer.storage.type=metadata
    druid.indexer.storage.recentlyFinishedThreshold=PT24H
    druid.indexer.tasklock.forceTimeChunkLock=true
    druid.indexer.tasklock.batchSegmentAllocation=true
    druid.indexer.tasklock.batchAllocationWaitTime=500
    druid.indexer.queue.maxSize=100
    druid.indexer.queue.startDelay=PT1M
    druid.indexer.queue.restartDelay=PT30S
    druid.indexer.queue.storageSyncRate=PT1M
    druid.indexer.runner.taskAssignmentTimeout=PT60M
    druid.indexer.runner.minWorkerVersion="0"
    druid.indexer.runner.parallelIndexTaskSlotRatio=1
    druid.indexer.runner.taskCleanupTimeout=PT60M
    druid.indexer.runner.taskShutdownLinkTimeout=PT60M
    druid.indexer.runner.pendingTasksRunnerNumThreads=1
    druid.indexer.runner.maxRetriesBeforeBlacklist=5
    druid.indexer.runner.workerBlackListBackoffTime=PT60M
    druid.indexer.runner.workerBlackListCleanupPeriod=PT60M
    druid.indexer.runner.maxPercentageBlacklistWorkers=20
    druid.indexer.runner.javaOptsArray=["-XX:+HeapDumpOnOutOfMemoryError"]
    druid.supervisor.storeStackTrace=false
    druid.supervisor.healthinessThreshold=3
    druid.supervisor.unhealthinessThreshold=3
    druid.supervisor.taskHealthinessThreshold=3
    druid.supervisor.taskUnhealthinessThreshold=3
    druid.supervisor.maxStoredExceptionEvents=3
    druid.supervisor.idleConfig.enabled=false
    druid.supervisor.idleConfig.inactiveAfterMillis=600000
    druid.indexer.runner.namespace=druid
    druid.indexer.runner.debugJobs=false
    druid.indexer.runner.disableClientProxy=false
    druid.indexer.runner.maxTaskDuration=PT6H
    druid.indexer.runner.taskCleanupDelay=P1D
    druid.indexer.runner.taskCleanupInterval=PT1H
    druid.indexer.runner.K8sjobLaunchTimeout=PT1H
    druid.indexer.runner.graceTerminationPeriodSeconds=PT90S
    druid.indexer.task.encapsulatedTask=true
    druid.indexer.runner.capacity=10
    druid.processing.intermediaryData.storage.type=deepstore
    druid.indexer.runner.k8s.adapter.type=customTemplateAdapter
    druid.indexer.runner.k8s.podTemplate.base=/opt/druid/conf/druid/cluster/task/task-base.yaml
    druid.indexer.runner.k8s.podTemplate.index_parallel=/opt/druid/conf/druid/cluster/task/task-base.yaml
    druid.indexer.runner.k8s.podTemplate.index_kafka=/opt/druid/conf/druid/cluster/task/task-base.yaml
    druid.indexer.runner.k8s.podTemplate.index_kinesis=/opt/druid/conf/druid/cluster/task/task-base.yaml
    druid.indexer.runner.k8s.podTemplate.compact=/opt/druid/conf/druid/cluster/task/task-base.yaml
    druid.indexer.runner.k8s.podTemplate.kill=/opt/druid/conf/druid/cluster/task/task-base.yaml
    druid.indexer.runner.k8s.podTemplate.query_controller=/opt/druid/conf/druid/cluster/task/task-base.yaml
  jvm: |-
    -Xms9g
    -Xmx9g

historical:
  metadata:
    labels: { }
    annotations:
      "k8s.grafana.com/job": "integrations/druid-historical"
  replicas: 1
  resources:
    requests:
      cpu: 3500m
      memory: 40Gi
    limits:
      cpu: 14000m
      memory: 120Gi
  node:
    selector:
      "karpenter.k8s.aws/instance-family": "i3"
    limits:
      cpu: 100
      memory: 1000Gi
    disruption:
      consolidateAfter: 10m
      consolidationPolicy: WhenEmpty
    requirements:
      - key: "karpenter.k8s.aws/instance-family"
        operator: In
        values: [ "i3" ]
  volumes:
    - name: druid-historical-conf
      configMap:
        name: "druid-v1-historical-conf"
  volumeMounts:
    - name: druid-historical-conf
      mountPath: /opt/druid/conf/druid/cluster/data/historical
      readOnly: true
  runtime: |-
    druid.bindOnHost=false
    druid.tlsPort=8283
    druid.service=druid/historical
    druid.server.maxSize=120g
    druid.server.tier=_default_tier
    druid.server.priority=0
    druid.segmentCache.locations=[{"path":"/var/druid/segment-cache","maxSize":"120g"}]
    druid.segmentCache.locationSelector.strategy=leastBytesUsed
    druid.segmentCache.deleteOnRemove=true
    druid.segmentCache.dropSegmentDelayMillis=30000
    druid.segmentCache.infoDir=/var/druid/segment/info
    druid.segmentCache.announceIntervalMillis=5000
    druid.segmentCache.numLoadingThreads=2
    druid.segmentCache.numBootstrapThreads=2
    druid.segmentCache.lazyLoadOnStart=false
    druid.coordinator.loadqueuepeon.curator.numCallbackThreads=2
    druid.segmentCache.numThreadsToLoadSegmentsIntoPageCacheOnDownload=0
    druid.segmentCache.numThreadsToLoadSegmentsIntoPageCacheOnBootstrap=0
    druid.server.http.numThread=42
    druid.server.http.maxIdleTime=PT5M
    druid.server.http.enableRequestLimit=false
    druid.server.http.defaultQueryTimeout=300000
    druid.server.http.gracefulShutdownTimeout=PT30S
    druid.server.http.unannouncePropagationDelay=PT0S
    druid.server.http.maxRequestHeaderSize=10000
    druid.processing.buffer.sizeBytes=125000000
    druid.processing.formatString=processing-%s
    druid.processing.numMergeBuffers=3
    druid.processing.numThreads=12
    druid.processing.fifo=true
    druid.processing.tmpDir=/var/druid/query/tmp
    druid.historical.cache.useCache=false
    druid.historical.cache.populateCache=false
    druid.historical.cache.maxEntrySize=1000000
    druid.monitoring.monitors=["org.apache.druid.java.util.metrics.JvmMonitor", "org.apache.druid.java.util.metrics.JvmCpuMonitor", "org.apache.druid.java.util.metrics.JvmThreadsMonitor", "org.apache.druid.server.metrics.HistoricalMetricsMonitor"]
  jvm: |-
    -Xms8g
    -Xmx8g
    -XX:MaxDirectMemorySize=40g

task:
  base:
    metadata:
      labels: { }
      annotations:
        "k8s.grafana.com/job": "integrations/druid-task"
    resources:
      requests:
        cpu: 3000m
        memory: 28Gi
      limits:
        cpu: 7000m
        memory: 58Gi
    node:
      selector:
        "karpenter.k8s.aws/instance-family": "i3"
      limits:
        cpu: 100
        memory: 1000Gi
      disruption:
        consolidateAfter: 10m
        consolidationPolicy: WhenEmpty
      requirements:
        - key: "karpenter.k8s.aws/instance-family"
          operator: In
          values: [ "i3" ]
    volumes:
      - name: task-conf
        configMap:
          name: "druid-v1-task-base-conf"
          defaultMode: 420
    volumeMounts:
      - name: task-conf
        mountPath: /opt/druid/conf/druid/cluster/master/coordinator-overlord
        readOnly: true
    runtime: |-
      druid.bindOnHost=false
      druid.tlsPort=8091
      druid.peon.mode=remote
      druid.service=druid/peon
      druid.server.http.numThreads=36
      druid.indexer.runner.type=k8s
      druid.indexer.task.encapsulatedTask=true
      druid.indexer.task.baseTaskDir=/var/druid/task
    jvm: |-
      -server
      -XX:+UseG1GC
      -XX:+ExitOnOutOfMemoryError
      -Duser.timezone=UTC
      -Dfile.encoding=UTF-8
      -Djava.io.tmpdir=/var/druid
      -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
